import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, classification_report

class SigmoidClassifier:
    def __init__(self, eta=0.05, max_iter=1000, plot=False):
        self.eta = eta  # Learning rate
        self.max_iter = max_iter  # Maximum number of iterations
        self.plot = plot  # Control whether to plot during training
        self.weights = None  # Placeholder for weights
        self.removed_features = []  # To store removed features due to multicollinearity

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def check_multicollinearity(self, X):
        corr_matrix = pd.DataFrame(X).corr().abs()
        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        to_drop = [column for column in upper.columns if any(upper[column] > 0.7)]
        if to_drop:
            self.removed_features = to_drop
            print(f"Removing features due to multicollinearity: {to_drop}")
            X = np.delete(X, to_drop, axis=1)
        return X

    def fit(self, X, Y):
        # Check and remove multicollinear features
        X = self.check_multicollinearity(X)
        
        self.weights = np.ones(X.shape[1])
        print(f"The Learning Rate is {self.eta}")
        print(f"The initial Weights are {self.weights}")

        for epoch in range(1, self.max_iter + 1):
            w_old = self.weights.copy()
            print(f"Running Epoch {epoch} ============>")
            for i in range(len(X)):
                yhat = np.dot(X[i], self.weights)
                sigmoidt = self.sigmoid(yhat)
                self.weights += self.eta * (Y[i] - sigmoidt) * X[i]
            
            print(f"Old Weights {w_old}")
            print(f"New Weights: {self.weights if not np.allclose(w_old, self.weights) else 'None'}")

            if self.plot and X.shape[1] == 3:  # Plotting only if we have 2 features + bias
                self.plot_graph(X, Y)
            
            if np.allclose(w_old, self.weights):
                print(f"Converged after {epoch} epochs")
                break

    def plot_graph(self, X, Y):
        plt.figure(figsize=(10, 6))
        x1_min, x1_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        x2_min, x2_max = X[:, 2].min() - 1, X[:, 2].max() + 1
        xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, 100), np.linspace(x2_min, x2_max, 100))
        grid = np.c_[np.ones(xx1.ravel().shape), xx1.ravel(), xx2.ravel()]
        probs = self.sigmoid(np.dot(grid, self.weights)).reshape(xx1.shape)

        plt.contourf(xx1, xx2, probs, alpha=0.8, levels=[0, 0.5, 1], cmap='coolwarm')
        plt.scatter(X[:, 1], X[:, 2], c=Y, edgecolors='k', marker='o', cmap='coolwarm')
        plt.title('Decision Boundary')
        plt.xlabel('x1')
        plt.ylabel('x2')
        plt.show()

    def predict(self, X):
        if self.removed_features:
            X = np.delete(X, self.removed_features, axis=1)
        yhat = np.dot(X, self.weights)
        return np.where(self.sigmoid(yhat) >= 0.5, 1, 0)

    def evaluate(self, X, Y):
        predictions = self.predict(X)
        accuracy = accuracy_score(Y, predictions)
        report = classification_report(Y, predictions)
        print(f"Accuracy: {accuracy}")
        print(f"Classification Report:\n{report}")

# Example usage:

# Load Iris dataset
from sklearn.datasets import load_iris
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.DataFrame(iris.target, columns=['y'])
df = pd.DataFrame(X)
df['y'] = y
df = df[df['y'] != 2]  # Only use two classes for binary classification
df['bias'] = 1

# Prepare the data
X = np.array(df[['sepal length (cm)', 'sepal width (cm)','petal length (cm)', 'petal width (cm)','bias']])
Y =df['y']

# Sigmoid Classification on Iris dataset
sigmoid_classifier_iris = SigmoidClassifier(eta=0.05, max_iter=100000, plot=False)
sigmoid_classifier_iris.fit(X, Y)
sigmoid_classifier_iris.evaluate(X, Y)
